# Smoke and Acceptance Testing

## Smoke Testing

A smoke test involves a minimal amount of testing that can be done to ensure that the system, under test is ready for further testing. It can be thought of as a guard to further testing - unless the system can perform some minimal operations, you don't move on to running a full test suite. This is usually a small number of tests, checking that the software can be installed, that major functionality seems to work and that no obvious problems appear.

For example, if you are testing an e-commerce site, you may check to see that a user can access the site, search for an item, and add it to their shopping cart. The full test suite would check numerous edge cases and paths, as well as all of the ancillary functionality such as recommendations and reviews. As another example, smoke testing a compiler might involve checking that it can compile a “hello, world” program and that the resulting executable does in fact print out “hello, world”. It would not include checking what happens when there are complex Boolean expressions, or if a referenced library is missing, or whether an unparseable program will produce the appropriate error message. It just determines that the system is able to perform basic functionality. This is often useful when a system should either work entirely or not at all, such as when installing a piece of software on a new architecture. If the code is compiled incorrectly, there is a good chance the software will fail to start. Smoke testing will allow us to bypass all of the work of setting up an appropriate test environment if the software simply doesn’t work at all.

Smoke testing allows you to determine whether the software is even worth testing before running the full test suite on it. There is often a cost associated with setting up a system for testing, such as installing software on servers and clients, looking up test plans, and generating test data.

Smoke testing can be either scripted or unscripted. In unscripted testing, an experienced tester or user just “plays around” with the software for a little while before the actual testing occurs. This is usually done by someone experienced with the software, so as to ensure that the most important functionality is tested, known defects have been fixed, and the software generally behaves as it should. Scripted testing means that there is a specific test plan that specifies the test cases to be executed. While scripted testing provides a much more regulated environment and helps to keep track of what has been shown to work, unscripted testing is much more flexible and allows testers to check different aspects of the software for different releases.

## Acceptance Testing

Smoke testing checks if the software is ready to be tested; in other words, can the software be accepted by the testing team in order to perform some other work on it? It is a subset of acceptance testing. Acceptance testing is any kind of testing that checks that the system is acceptable to continue to the next phase of its life cycle, be it testing, or delivery to a customer, or making it ready for a user.

Depending on the domain, acceptance tests may be scripted or unscripted. For large contracting companies or complex projects, there are often several test plans verifying that multiple parts of the system operate correctly, and metrics for quality (e.g., no more than three major defects will be found during the test period) which must be met. For smaller programs, it may be as simple as allowing the customer or user to sit down with the software for a few minutes and give a thumbs-up or a thumbs-down.

**Operational testing**, also called **field testing** is testing the system under real-life(operating) conditions. Often, a problem is not found, or even thought of, during the development process or when checked piece-by-piece. Operational testing can find these overlooked errors by actually running the system in a real-life environment.

Another kind of acceptance testing is **user acceptance testing**. Commonly used in Agile environments, user acceptance testing (UAT) checks that the system meets the goals of the users and operates in a manner acceptable to them.Usually, a subject matter expert (SME—a non-developer with understanding of the domain the software is written for) is given a number of tasks to perform. The SME is given no instructions as to how to do the tasks by the person doing the testing; it is up to the SME to figure out how to use the software (using appropriate documentation or other supporting material) to complete the tasks.

One can think of alpha testing and beta testing as kinds of acceptance tests. Although the terms can have slightly different meanings in different domains, they both involve having independent users or teams using the software under development.

In all cases, alpha testing precedes beta testing, if any alpha testing is done. Alpha testing involves a very small, select group of customers—often those of high value or with high technical skill—using the software. In some cases, it may actually not be a customer doing the testing, but a testing group external to the group that developed the system. Beta testing involves a broader release of the software to a variety of customers. This often occurs after alpha testing for large, well-tested software projects. However, there is nothing to stop a team from skipping alpha testing entirely and sending software straight out to a large group of people—perhaps the entire customer base—with the understanding that the software is a beta version.

With online systems, oftentimes beta testing can be “mixed in” with regular usage of the system. You can have a specific subset of users—say, those who have shown an interest in trying new features, or customers important for revenue, or even a random sampling—have access to the new functionality you wish to beta test. Usually, you want to either clear it with these customers or make sure that they know that the functionality they are using is not considered complete.
