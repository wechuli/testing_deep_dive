You can find virtually all of the defects that a comprehensive test approach would find while using orders of magnitude less testing time and resources. This technique is called combinatorial testing. Testing all possible pairs of values is a kind of combinatorial testing, but has its own term, pairwise testing or all-pairs testing.

## Stochastic and Property-Based Testing

Stochastic testing is black box testing, random testing, performed by automated testing tools. Stochastic testing is a series of random tests over time. Stochastic testing is also referred to as monkey testing.

Since you - or more precisely, the stochastic testing system- may not know exactly what the expected behavior should be for a given input, you need to check for properties of the system. At the unit testing level, where you are checking individual methods, this is called **property-based testing**

### Smart, Dumb, Evil and Chaos Monkeys

- **Dumb Monkey** testing is sending in just any old input you can think of.
- **Smart monkey** - testing involves using input which a user might conceivably enter, as opposed to being strictly random. Creating a smart monkey test can be difficult, because not only do you have to first understand what users would likely do with the application, but then develop a model for it. However, the smart monkey is much more likely to discover a defect in the system under test.
- **Evil monkey** - testing simulates a malicious user who is actively trying to hurt your system. This can be through sending very long strings, potential injection attacks, malformed data, or other inputs which are designed to cause havoc in your system. In today's networked world, systems are almost always under attack if they are connected to the Internet.
- **Chaos Monkey** - is a tool developed by Netflix which randomly shuts down servers that their system is running on, in order to simulate random outages. For any large system, servers will go down on a regular basis, and at any given time, some percentage of systems will be unavailable. Chaos monkey testing ensures that the system as a whole will be able to operate effectively when when individual machines are not responding.

## Performance Testing

How you measure performance will be based upon the kind of system you are testing. That does not mean, however, that there are no rules or heuristics.

### Categories of Performance Indicators

Defining performance for a particular system means determining which performance indicators the user or customer cares about. Although there are a large number of possible perfoemance indicators, there are two main categories: service-oriented and efficiency-oriented.

A **service-oriented indicator** measures how well a system is providing a service to a particular user. These are measured from the user's perspective and quantify aspects of the system the user would directly care about. Some examples of service-oriented indicators would be average page load time, response time, or what percentage of the time the system is available.There are two main subcategories of service-oriented indicators. The first is availability—how available is the system to the user? This could mean anything from what percentage of the time can the system be accessed to how available different features are to the users at different times. The second main category is response time—how long does it take for the system to respond to the user’s input or return a result?

An **efficiency-oriented indicator** measures how efficiently a system makes use of available computational resources. You can think of these as being measured "from the program's point of view" or at least from the computer's point of view. Examples of efficiency-oriented indicators would be what percentage of CPU operations are being used for performing some functionality, how much disk space is being used, or how many concurrent users the system can handle on a particular server. Just like service-oriented indicators, there are two main subcategories in efficiency-oriented testing. Throughput measures how many events can the system handle in a given amount of time, such as how many users can log in at the same time, or how many packets can a system route in 30 seconds. Utilization measures what percentage or absolute amount of computing resources are used to perform a given task. For example, how much disk space does a database take to store a specified table? How much RAM is necessary when sorting it?

### Testing Performance: Thresholds and Targets

In order to determine whether or not a performance test has "passed", you need **performance targets** or specific quantitative values that the performance indicatos are supposed to reach

Targets, though, are the ideal. Oftentimes, a particular performance indicator for a system may not reach its target, or may not be able to. Performance thresholds indicate the point where a performance indicator reaches an absolutely minimal acceptable performance. For example, while the target for response time may be 500 milliseconds, systems engineers may have determined that the system would be releasable with a response time of 3000 milliseconds. It would not be great if it only met that mark, but if it takes any longer, the system would probably not be releasable. A system whose performance indicators merely meet the threshold should not be considered as “passing” that particular performance metric. There is still work to do! You can see that the standard “pass”/“fail” metric often used for functional testing is often not really appropriate for performance metrics. There are shades of gray, and they are often able to be manipulated. What kind of hardware are you running the tests on? What operating system? What other processes are running? Which web browser are you using to access the site? By changing these, the same system may show very different results on a performance test.

**Load testing** - In load testing, a system is set up and monitored while events are processed. The kind of events will depend on the system under test - for a webserver, for example, it might be page loads, or for a router, it would be packets routed. By using different kinds of load tests based on realistic assumptions, one can determine the MTBF and MTTR and thus the availability that users can expect to see.

A **baseline test** runs the system with few or no events to process, just to check that the system can in fact handle running for a given period of time. This is often not a realistic scenario—a system which never does much is not likely to be developed in the first place - but provides a "baseline" which future tests can compare results against. The opposite of a baseline test is a stress test, in which the system is "stressed" by having it process a large number of events in a small time frame.

A **stability test**, sometimes also called a soak test, is often the single most realistic load test that is run. During this kind of load test, a constant but small-to-medium number of events are processed over a long period of time, in order to determine that the system is in fact stable when doing realistic work.



